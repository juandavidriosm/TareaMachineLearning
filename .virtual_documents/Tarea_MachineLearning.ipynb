import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns


import jd

from sklearn.preprocessing import OrdinalEncoder,LabelEncoder
from category_encoders import TargetEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler

from imblearn.over_sampling import SMOTE, BorderlineSMOTE



import pycaret
from pycaret.classification import *


X = pd.read_csv("In/Training_set_values.csv")
y = pd.read_csv("In/Training_set_labels.csv")
X_test = pd.read_csv("In/Test_set_values.csv")
df = pd.merge(X,y,on="id")


from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df.status_group = le.fit_transform(df.status_group)



for i,j in df.dtypes.items():
    if j == "object":
        df[i] = df[i].astype("category")


df.dtypes


num_cols = df.select_dtypes(include = np.number).columns.tolist()
num_cols.remove("id")
num_cols.remove("status_group")

cat_cols= df.select_dtypes(exclude = np.number).columns.tolist()
cat_cols.remove("date_recorded")
cat_cols.remove("funder")
cat_cols.remove("installer")
cat_cols.remove("wpt_name")
cat_cols.remove("basin")


exp = setup(data=df, target='status_group', 
            numeric_features=num_cols, 
           categorical_features=["waterpoint_type_group","date_recorded","installer","wpt_name","basin","subvillage","region",
                                 "lga","ward",#"public_meeting","recorded_by","scheme_management","scheme_name"
                                 ],
            ignore_features=['id'])


best = exp.compare_models()


exp.plot_model(best,"confusion_matrix")


pred = exp.predict_model(best,X_test)
X_test_labels_pycaret = pred[["id","prediction_label"]]
X_test_labels_pycaret["prediction_label"] = le.inverse_transform(X_test_labels_pycaret.prediction_label)
X_test_labels_pycaret.rename(columns={"prediction_label":"status_group"},inplace=True)
X_test_labels_pycaret.to_csv("Out/predicciones_pycaret1.csv",index=None,sep=",")


pd.read_csv("Out/predicciones_pycaret1.csv")


X = pd.read_csv("In/Training_set_values.csv")
y = pd.read_csv("In/Training_set_labels.csv")
X_test = pd.read_csv("In/Test_set_values.csv")
df = pd.merge(X,y,on="id")




for i in X.select_dtypes(include = "O").columns:
    X[i] = df[i].astype("category")


from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
#df.status_group = le.fit_transform(df.status_group)


y["status_group"] = le.fit_transform(y.status_group)

drop_list  = ["management_group","permit","population","amount_tsh","num_private","recorded_by"]
X.drop(drop_list,axis=1,inplace=True)
X_test.drop(drop_list,axis=1,inplace=True)

cat_cols = X.select_dtypes(exclude=np.number).columns.tolist()
num_cols = X.select_dtypes(include=np.number).columns.tolist()


cat_cols = X.select_dtypes(exclude=np.number).columns.tolist()
cat_cols.append("district_code")
cat_cols.append("region_code")

num_cols = X.select_dtypes(include=np.number).columns.tolist()
num_cols.remove("id")
num_cols.remove("district_code")
num_cols.remove("region_code")

preprocessing = ColumnTransformer([
    ('target_enc', TargetEncoder(), cat_cols),  
    ('scaler', StandardScaler(), num_cols),  
],
remainder = "passthrough",
)
X = pd.DataFrame(data=preprocessing.fit_transform(X,y=y.status_group.values), columns=preprocessing.get_feature_names_out())
X_test = pd.DataFrame(data=preprocessing.transform(X_test), columns=preprocessing.get_feature_names_out())


rf = RandomForestClassifier()
rf.fit(X.to_numpy(),y.status_group.values)


X_test["predictions"] = rf.predict(X_test)


X_test.predictions = le.inverse_transform(X_test.predictions)
X_test = X_test[["remainder__id","predictions"]]
X_test.remainder__id = X_test.remainder__id.astype(int)

X_test.rename({"remainder__id":"id","predictions":"status_group"},axis=1,inplace=True)
X_test.to_csv("Out/predicciones_TargetEncoderStandardScaler.csv",index=None,sep=",")


X = pd.read_csv("In/Training_set_values.csv")
y = pd.read_csv("In/Training_set_labels.csv")
X_test = pd.read_csv("In/Test_set_values.csv")
df = pd.merge(X,y,on="id")

for i in X.select_dtypes(include = "O").columns:
    X[i] = df[i].astype("category")



y["status_group"] = le.fit_transform(y.status_group)

drop_list  = ["management_group","permit","population","amount_tsh","num_private","recorded_by"]
X.drop(drop_list,axis=1,inplace=True)
X_test.drop(drop_list,axis=1,inplace=True)

cat_cols = X.select_dtypes(exclude=np.number).columns.tolist()
num_cols = X.select_dtypes(include=np.number).columns.tolist()


cat_cols = X.select_dtypes(exclude=np.number).columns.tolist()
cat_cols.append("district_code")
cat_cols.append("region_code")

num_cols = X.select_dtypes(include=np.number).columns.tolist()
num_cols.remove("id")
num_cols.remove("district_code")
num_cols.remove("region_code")

preprocessing = ColumnTransformer([
    ('target_enc', OrdinalEncoder(handle_unknown="use_encoded_value",
                                  unknown_value=10000000,
                                  encoded_missing_value =10000000), cat_cols),  
    ('scaler', StandardScaler(), num_cols),  
],
remainder = "passthrough",
)
X = pd.DataFrame(data=preprocessing.fit_transform(X,y=y.status_group.values), columns=preprocessing.get_feature_names_out())
X_test = pd.DataFrame(data=preprocessing.transform(X_test), columns=preprocessing.get_feature_names_out())


X.isna().sum()


rf = RandomForestClassifier()
rf.fit(X.to_numpy(),y.status_group.values)
X_test["status_group"] = rf.predict(X_test)
X_test.remainder__id = X_test.remainder__id.astype(int)
X_test.rename({"remainder__id":"id","predictions":"status_group"},axis=1,inplace=True)


X_test = X_test[["id","status_group"]]
X_test.status_group = le.inverse_transform(X_test.status_group)
X_test.to_csv("Out/predicciones_OrdinalEncoderStandardScaler.csv",index=None,sep=",")









le = OrdinalEncoder()
label_enc = LabelEncoder()
X= pd.read_csv("Out/XReemplazoLongitudeLatitudeConClusters.csv")
y = pd.read_csv("In/Training_set_labels.csv")
X_test = pd.read_csv("Out/X_testReemplazoLongitudeLatitudeConClusters.csv")
df = pd.merge(X,y,on="id")

for i in X.select_dtypes(include = "O").columns:
    X[i] = df[i].astype("category")
    
y["status_group"] = label_enc.fit_transform(y.status_group)

drop_list  = ["management_group","permit","population","amount_tsh","num_private","recorded_by"]
X.drop(drop_list,axis=1,inplace=True)
X_test.drop(drop_list,axis=1,inplace=True)

cat_cols = X.select_dtypes(exclude=np.number).columns.tolist()
num_cols = X.select_dtypes(include=np.number).columns.tolist()


cat_cols = X.select_dtypes(exclude=np.number).columns.tolist()
cat_cols.append("district_code")
cat_cols.append("region_code")

num_cols = X.select_dtypes(include=np.number).columns.tolist()
num_cols.remove("id")
num_cols.remove("district_code")
num_cols.remove("region_code")

preprocessing = ColumnTransformer([
    ('target_enc', OrdinalEncoder(handle_unknown="use_encoded_value",
                                  unknown_value=10000000,
                                  encoded_missing_value =10000000), cat_cols),  
    ('scaler', StandardScaler(), num_cols),  
],
remainder = "passthrough",
)
X = pd.DataFrame(data=preprocessing.fit_transform(X,y=y.status_group.values), columns=preprocessing.get_feature_names_out())
X_test = pd.DataFrame(data=preprocessing.transform(X_test), columns=preprocessing.get_feature_names_out())

rf = RandomForestClassifier()
rf.fit(X.to_numpy(),y.status_group.values)
X_test["status_group"] = rf.predict(X_test)
X_test.remainder__id = X_test.remainder__id.astype(int)
X_test.rename({"remainder__id":"id","predictions":"status_group"},axis=1,inplace=True)



X_test = X_test[["id","status_group"]]
X_test.status_group = label_enc.inverse_transform(X_test.status_group)
X_test.to_csv("Out/predicciones_OrdinalEncoderStandardScaler7ClustersLoc.csv",index=None,sep=",")


# GradientBoosting da buenos resultados en cross_validate


X = pd.read_csv("In/Training_set_values.csv")
y = pd.read_csv("In/Training_set_labels.csv")
X_test = pd.read_csv("In/Test_set_values.csv")
df = pd.merge(X,y,on="id")

for i in X.select_dtypes(include = "O").columns:
    X[i] = df[i].astype("category")



le= LabelEncoder()
y["status_group"] = le.fit_transform(y.status_group)

drop_list  = ["management_group","permit","population","amount_tsh","num_private","recorded_by"]
X.drop(drop_list,axis=1,inplace=True)
X_test.drop(drop_list,axis=1,inplace=True)

cat_cols = X.select_dtypes(exclude=np.number).columns.tolist()
num_cols = X.select_dtypes(include=np.number).columns.tolist()


cat_cols = X.select_dtypes(exclude=np.number).columns.tolist()
cat_cols.append("district_code")
cat_cols.append("region_code")

num_cols = X.select_dtypes(include=np.number).columns.tolist()
num_cols.remove("id")
num_cols.remove("district_code")
num_cols.remove("region_code")

preprocessing = ColumnTransformer([
    ('target_enc', OrdinalEncoder(handle_unknown="use_encoded_value",
                                  unknown_value=10000000,
                                  encoded_missing_value =10000000), cat_cols),  
    ('scaler', StandardScaler(), num_cols),  
],
remainder = "passthrough",
)
X = pd.DataFrame(data=preprocessing.fit_transform(X,y=y.status_group.values), columns=preprocessing.get_feature_names_out())
X_test = pd.DataFrame(data=preprocessing.transform(X_test), columns=preprocessing.get_feature_names_out())


gradBoost = GradientBoostingClassifier()
gradBoost.fit(X.to_numpy(),y.status_group.values)
X_test["status_group"] = gradBoost.predict(X_test)
X_test.remainder__id = X_test.remainder__id.astype(int)
X_test.rename({"remainder__id":"id","predictions":"status_group"},axis=1,inplace=True)


X_test = X_test[["id","status_group"]]
X_test.status_group = le.inverse_transform(X_test.status_group)
X_test.to_csv("Out/GradBoostpredicciones_OrdinalEncoderStandardScaler.csv",index=None,sep=",")








X = pd.read_csv("In/Training_set_values.csv")
y = pd.read_csv("In/Training_set_labels.csv")
X_test = pd.read_csv("In/Test_set_values.csv")
df = pd.merge(X,y,on="id")
sm = SMOTE(random_state=23,sampling_strategy = "not majority")

for i in X.select_dtypes(include = "O").columns:
    X[i] = df[i].astype("category")

le= LabelEncoder()
y["status_group"] = le.fit_transform(y.status_group)

drop_list  = ["management_group","permit","population","amount_tsh","num_private","recorded_by"]
X.drop(drop_list,axis=1,inplace=True)
X_test.drop(drop_list,axis=1,inplace=True)

cat_cols = X.select_dtypes(exclude=np.number).columns.tolist()
num_cols = X.select_dtypes(include=np.number).columns.tolist()


cat_cols = X.select_dtypes(exclude=np.number).columns.tolist()
cat_cols.append("district_code")
cat_cols.append("region_code")

num_cols = X.select_dtypes(include=np.number).columns.tolist()
num_cols.remove("id")
num_cols.remove("district_code")
num_cols.remove("region_code")

preprocessing = ColumnTransformer([
    ('target_enc', OrdinalEncoder(handle_unknown="use_encoded_value",
                                  unknown_value=10000000,
                                  encoded_missing_value =10000000), cat_cols),  
    ('scaler', StandardScaler(), num_cols),  
],
remainder = "passthrough",
)
X = pd.DataFrame(data=preprocessing.fit_transform(X,y=y.status_group.values), columns=preprocessing.get_feature_names_out())
X_test = pd.DataFrame(data=preprocessing.transform(X_test), columns=preprocessing.get_feature_names_out())

X, y = sm.fit_resample(X, y.status_group.values)

rf = RandomForestClassifier()
rf.fit(X.to_numpy(),y)
X_test["status_group"] = rf.predict(X_test)
X_test.remainder__id = X_test.remainder__id.astype(int)
X_test.rename({"remainder__id":"id","predictions":"status_group"},axis=1,inplace=True)


X_test = X_test[["id","status_group"]]
X_test.status_group = le.inverse_transform(X_test.status_group)
X_test.to_csv("Out/RandomForestSMOTEnot_majority.csv",index=None,sep=",")





X = pd.read_csv("In/Training_set_values.csv")
y = pd.read_csv("In/Training_set_labels.csv")
X_test = pd.read_csv("In/Test_set_values.csv")
df = pd.merge(X,y,on="id")
sm = SMOTE(random_state=23,sampling_strategy = "minority")

for i in X.select_dtypes(include = "O").columns:
    X[i] = df[i].astype("category")

le= LabelEncoder()
y["status_group"] = le.fit_transform(y.status_group)

drop_list  = ["management_group","permit","population","amount_tsh","num_private","recorded_by"]
X.drop(drop_list,axis=1,inplace=True)
X_test.drop(drop_list,axis=1,inplace=True)

cat_cols = X.select_dtypes(exclude=np.number).columns.tolist()
num_cols = X.select_dtypes(include=np.number).columns.tolist()


cat_cols = X.select_dtypes(exclude=np.number).columns.tolist()
cat_cols.append("district_code")
cat_cols.append("region_code")

num_cols = X.select_dtypes(include=np.number).columns.tolist()
num_cols.remove("id")
num_cols.remove("district_code")
num_cols.remove("region_code")

preprocessing = ColumnTransformer([
    ('target_enc', OrdinalEncoder(handle_unknown="use_encoded_value",
                                  unknown_value=10000000,
                                  encoded_missing_value =10000000), cat_cols),  
    ('scaler', StandardScaler(), num_cols),  
],
remainder = "passthrough",
)
X = pd.DataFrame(data=preprocessing.fit_transform(X,y=y.status_group.values), columns=preprocessing.get_feature_names_out())
X_test = pd.DataFrame(data=preprocessing.transform(X_test), columns=preprocessing.get_feature_names_out())

X, y = sm.fit_resample(X, y.status_group.values)

rf = RandomForestClassifier()
rf.fit(X.to_numpy(),y)
X_test["status_group"] = rf.predict(X_test)
X_test.remainder__id = X_test.remainder__id.astype(int)
X_test.rename({"remainder__id":"id","predictions":"status_group"},axis=1,inplace=True)


X_test = X_test[["id","status_group"]]
X_test.status_group = le.inverse_transform(X_test.status_group)
X_test.to_csv("Out/RandomForestSMOTEminority.csv",index=None,sep=",")


# queda por intentar con más técnicas, dejando clusters y continuas
